# ğŸ’³ 2025 TOSS NEXT ML CHALLENGE: CTR Prediction

> **ì œ4íšŒ í† ìŠ¤ NEXT ê°œë°œì ì±Œë¦°ì§€ - ê´‘ê³  í´ë¦­ ì˜ˆì¸¡(CTR) ëª¨ë¸ ê°œë°œ** \> Transformer ê¸°ë°˜ì˜ Hybrid Tabular Modelì„ í™œìš©í•œ ê´‘ê³  í´ë¦­ë¥  ì˜ˆì¸¡ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

## ğŸ“Œ Competition Overview

  * **ëŒ€íšŒëª…:** í† ìŠ¤ NEXT ML CHALLENGE : ê´‘ê³  í´ë¦­ ì˜ˆì¸¡(CTR) ëª¨ë¸ ê°œë°œ
  * **ì£¼ìµœ/ì£¼ê´€:** Viva Republica (Toss) / DACON
  * **ë§í¬:** [DACON Competition Page](https://dacon.io/competitions/official/236575/overview/description)
  * **ëª©í‘œ:** ìœ ì €ì˜ í–‰ë™ ë¡œê·¸ì™€ ê´‘ê³  ì†ì„± ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´‘ê³  í´ë¦­ ì—¬ë¶€(`clicked`)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì´ì§„ ë¶„ë¥˜(Binary Classification) ëª¨ë¸ ê°œë°œ.

## ğŸ“ Dataset Description

ì´ 119ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ í™œìš©í–ˆìŠµë‹ˆë‹¤.

| Feature Type | Columns | Description |
| :--- | :--- | :--- |
| **Target** | `clicked` | ê´‘ê³  í´ë¦­ ì—¬ë¶€ (0/1) |
| **User Info** | `gender`, `age_group` | ìœ ì € ì„±ë³„ ë° ì—°ë ¹ëŒ€ |
| **Context** | `day_of_week`, `hour`, `inventory_id` | ë…¸ì¶œ ìš”ì¼, ì‹œê°„, ì§€ë©´ ID |
| **Sequence** | `seq` | ìœ ì €ì˜ ê³¼ê±° ì„œë²„ ë¡œê·¸ ì‹œí€€ìŠ¤ (Sequential Data) |
| **Ad Attributes** | `l_feat_*` | ê´‘ê³  ì†ì„± ì •ë³´ (14ë²ˆ: Ads set ë“±) |
| **Information** | `feat_a~e_*` | ì •ë³´ ì˜ì—­ë³„ ì„¸ë¶€ í”¼ì²˜ |
| **History** | `history_a_*` | ê³¼ê±° ì¸ê¸°ë„ ë° ì´ë ¥ ì •ë³´ |

## ğŸ—ï¸ Model Architecture: Transformer for Tabular & Sequence

ë³¸ ì†”ë£¨ì…˜ì€ ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…(ë²”ì£¼í˜•, ìˆ˜ì¹˜í˜•, ì‹œí€€ìŠ¤)ì„ íš¨ê³¼ì ìœ¼ë¡œ ìœµí•©í•˜ê¸° ìœ„í•´ **Transformer Encoder** ê¸°ë°˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ê°ê¸° ë‹¤ë¥¸ ì„±ê²©ì˜ ë°ì´í„°ë¥¼ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ì¸ì½”ë”©í•œ ë’¤, ì´ë¥¼ 'í† í°(Token)'í™”í•˜ì—¬ Transformerê°€ í”¼ì²˜ ê°„ì˜ ìƒí˜¸ì‘ìš©(Interaction)ì„ í•™ìŠµí•˜ë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.

### Model Diagram
<img width="960" height="540" alt="image" src="https://github.com/user-attachments/assets/259f44c5-bddd-41fa-a78a-5080302804b5" />
<img width="960" height="540" alt="image" src="https://github.com/user-attachments/assets/bb47eab1-ab08-4bfd-8a2d-b6a21496232e" />


### Key Components

1.  **Multi-Modal Inputs Processing:**

      * **Categorical:** `nn.Embedding`ì„ í†µí•´ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ í›„, Linear Projectionì„ í†µí•´ í† í°í™”.
      * **Numerical:** MLP(Linear -\> ReLU -\> Linear)ë¥¼ í†µê³¼ì‹œì¼œ ì••ì¶•ëœ ì •ë³´ë¥¼ í† í°í™”.
      * **Sequential (`seq`):** `nn.LSTM`ì„ í™œìš©í•˜ì—¬ ê°€ë³€ ê¸¸ì´ì˜ ìœ ì € ë¡œê·¸ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê³ , ë§ˆì§€ë§‰ Hidden Stateë¥¼ ì¶”ì¶œí•˜ì—¬ ì‹œí€€ìŠ¤ ë¬¸ë§¥ ì •ë³´ë¥¼ ë‹´ì€ í† í° ìƒì„±.

2.  **Transformer Encoder:**

      * ë²”ì£¼í˜•, ìˆ˜ì¹˜í˜•, ì‹œí€€ìŠ¤ ëª¨ë“ˆì—ì„œ ìƒì„±ëœ ì„ë² ë”©ë“¤ì„ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤(`[Cat_Token, Num_Token, Seq_Token]`)ë¡œ ê²°í•©.
      * Self-Attention ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë°ì´í„° íƒ€ì… ê°„ì˜ ë³µì¡í•œ ìƒê´€ê´€ê³„ë¥¼ í•™ìŠµ.

3.  **Prediction Head:**

      * ì¸ì½”ë”©ëœ ì •ë³´ë¥¼ Flattení•˜ì—¬ MLPë¥¼ í†µê³¼ì‹œì¼œ ìµœì¢… í´ë¦­ í™•ë¥  ì˜ˆì¸¡.

## ğŸ’» Code Structure

### `TransformerTabularModel`

```python
# í•µì‹¬ ëª¨ë¸ ì•„í‚¤í…ì²˜ (Hybrid Transformer)
class TransformerTabularModel(nn.Module):
    def __init__(self, ...):
        # 1. Embedding & Projection
        self.cat_proj = nn.Linear(total_cat_emb_dim, 64)
        self.num_mlp = nn.Sequential(...) 
        
        # 2. Sequence Processing (LSTM)
        self.lstm = nn.LSTM(...) 
        
        # 3. Transformer Encoder (Feature Interaction)
        self.transformer = nn.TransformerEncoder(...)
        
        # 4. Final Classification
        self.final_mlp = nn.Sequential(...)

    def forward(self, cat_x, num_x, seq_x, seq_lengths):
        # ... (Forward propagation logic)
        tokens = torch.cat([cat_token, num_token, seq_token], dim=1)
        transformed = self.transformer(tokens)
        logits = self.final_mlp(pooled).squeeze(1)
        return logits
```

## âš™ï¸ Development Environment

  * **Language:** Python 3.x
  * **Deep Learning Framework:** PyTorch
  * **Libraries:**
      * `pandas`, `numpy`: ë°ì´í„° ì „ì²˜ë¦¬
      * `scikit-learn`: ë ˆì´ë¸” ì¸ì½”ë”© ë° ìŠ¤ì¼€ì¼ë§
      * `torch`: ëª¨ë¸ êµ¬í˜„ ë° í•™ìŠµ

## ğŸš€ How to Run

1.  **ë°ì´í„° ì¤€ë¹„:**
      * DACON ëŒ€íšŒ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ `./data` ê²½ë¡œì— ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.
2.  **ì „ì²˜ë¦¬ ë° í•™ìŠµ:**
      * ì œê³µëœ ë…¸íŠ¸ë¶ `TOSS_T2G_low.ipynb`ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
      * ë…¸íŠ¸ë¶ ë‚´ì—ëŠ” ë°ì´í„° ë¡œë“œ, ì „ì²˜ë¦¬(ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì¸ì½”ë”©), ëª¨ë¸ í•™ìŠµ, ì¶”ë¡  ê³¼ì •ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

-----

### ğŸ“ˆ Future Works

  * **Feature Engineering:** `seq` ë°ì´í„° ì™¸ì— ì‹œê°„ íë¦„ì— ë”°ë¥¸ íŒŒìƒ ë³€ìˆ˜ ì¶”ê°€ ìƒì„±.
  * **Ensemble:** Tree ê¸°ë°˜ ëª¨ë¸(XGBoost, CatBoost)ê³¼ Transformer ëª¨ë¸ì˜ ì•™ìƒë¸”ì„ í†µí•œ ì„±ëŠ¥ ê·¹ëŒ€í™”.
  * **Hyperparameter Tuning:** Transformer layer ìˆ˜ ë° Head ìˆ˜ ìµœì í™”.
